{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(5,784)\n",
    "b = torch.randn(784,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.7907,  1.0112, -0.8297,  ..., -0.3511,  0.4576,  0.1291],\n",
       "         [ 0.1918, -0.7470, -0.3927,  ...,  0.0692,  0.4960,  0.5979],\n",
       "         [-0.4534,  1.0865,  0.4031,  ..., -0.3946,  1.5603,  2.0023],\n",
       "         [-0.1760, -2.7591,  1.0126,  ...,  0.7163,  0.5890,  0.1119],\n",
       "         [-0.6466, -0.9701, -0.8949,  ..., -1.4830, -0.2630,  0.5843]]),\n",
       " tensor([[-0.4702, -1.0919, -1.0979,  ..., -0.2159,  0.2466, -1.2393],\n",
       "         [-0.8525,  0.4899, -0.5190,  ..., -0.3861, -0.0492, -0.4300],\n",
       "         [ 1.5356, -0.0636,  0.2483,  ...,  1.1509,  0.3055,  0.5325],\n",
       "         ...,\n",
       "         [-0.8914,  1.2675, -0.4003,  ..., -0.7347, -0.4699,  0.0584],\n",
       "         [ 2.1745,  0.9923,  1.6917,  ..., -0.8474, -0.4459, -1.7510],\n",
       "         [-0.6510, -0.5975, -0.6276,  ...,  0.9200,  0.6085, -0.3840]]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.6 µs ± 4.48 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 a@b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Straightforward loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slow_matmul(a, b):\n",
    "    assert a.shape[1] == b.shape[0]  # Otherwise you can't multiply a and b.\n",
    "    rows_a = a.shape[0]\n",
    "    common_dim = a.shape[1]\n",
    "    cols_b = b.shape[1]\n",
    "    output = torch.zeros(rows_a, cols_b)\n",
    "    for i in range(rows_a):\n",
    "        for j in range(cols_b):\n",
    "            for k in range(common_dim):\n",
    "                output[i,j] += a[i,k] * b[k,j]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing floats is a little fiddly due to precision and rounding errors!\n",
    "torch.allclose(slow_matmul(a,b), a@b, rtol=1e-5, atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 902 ms, sys: 72 µs, total: 902 ms\n",
      "Wall time: 902 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-25.3802, -39.0457,  -2.8763,   8.0384,  17.4018, -23.1719,  22.7924,\n",
       "         -30.0939,  34.7306,  -8.4432],\n",
       "        [ 14.3616,  -1.3186,   9.9665, -15.9873, -20.0919,  18.0664,  13.3102,\n",
       "          19.4809,  21.0659,   7.5077],\n",
       "        [-41.6030, -30.6106,   9.2916, -12.5558,  22.2696,  -5.0116,  22.1513,\n",
       "          -4.4115,  39.1963, -63.4013],\n",
       "        [ 18.7230,  15.5820,  25.9895, -51.9905, -10.6715, -19.1673, -15.5803,\n",
       "           0.2417,  36.0474,  27.3397],\n",
       "        [-15.7743, -14.9407,   5.5782,  39.4856,  21.0562,  29.1491,  16.8582,\n",
       "          -3.1518, -29.5479,   3.2722]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time slow_matmul(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With elementwise multiplication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elementwise_matmul(a, b):\n",
    "    assert a.shape[1] == b.shape[0]  # Otherwise you can't multiply a and b.\n",
    "    rows_a = a.shape[0]\n",
    "    cols_b = b.shape[1]\n",
    "    output = torch.zeros(rows_a, cols_b)\n",
    "    for i in range(rows_a):\n",
    "        for j in range(cols_b):\n",
    "            output[i,j] = (a[i,:] * b[:,j]).sum()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(elementwise_matmul(a,b), a@b, rtol=1e-5, atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.59 ms ± 662 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 elementwise_matmul(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def broadcasting_matmul(a, b):\n",
    "    assert a.shape[1] == b.shape[0]  # Otherwise you can't multiply a and b.\n",
    "    rows_a = a.shape[0]\n",
    "    cols_b = b.shape[1]\n",
    "    output = torch.zeros(rows_a, cols_b)\n",
    "    for i in range(rows_a):\n",
    "        output[i] = (a[i,:].unsqueeze(-1) * b).sum(dim=0)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(broadcasting_matmul(a,b), a@b, rtol=1e-5, atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456 µs ± 113 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 broadcasting_matmul(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def einsum_matmul(a, b):\n",
    "    assert a.shape[1] == b.shape[0]  # Otherwise you can't multiply a and b.\n",
    "    return torch.einsum(\"ik,kj->ij\", a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(einsum_matmul(a,b), a@b, rtol=1e-5, atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 µs ± 37.9 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 einsum_matmul(a,b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
